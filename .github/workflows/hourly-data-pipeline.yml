name: Hourly Data Pipeline

on:
  schedule:
    - cron: '0 * * * *'  # Run every hour
  workflow_dispatch:  # Allow manual triggering

jobs:
  run-data-pipeline:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install jupyter nbconvert pandas numpy boto3 requests matplotlib seaborn scikit-learn shap python-dotenv 
          
      - name: Run feature extraction from API
        run: |
          jupyter nbconvert --to script notebooks/01_data_fetch_hourly.ipynb
          python notebooks/01_data_fetch_hourly.py
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          
      - name: Run EDA and cleaning
        run: |
          jupyter nbconvert --to script notebooks/02_EDA.ipynb
          python notebooks/02_EDA.py
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}